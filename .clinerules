# ICT 情感分析项目规则

## 项目概述
这是一个基于多模态（图像-文本-标题）的情感分析深度学习项目。
- 模型名称：ICT (Image-Caption-Text)
- 任务：社交媒体情感分析
- 数据集：Twitter 2017 多模态情感分析数据集

## 核心模块
1. **CFM** (Cross-modal Fusion Module) - 跨模态融合模块
2. **CRM** (Cross-modal Refinement Module) - 跨模态精炼模块
3. **DDM** (Dynamic Dependency Module) - 动态依赖模块
4. **Sentiment Stream** - 情感流模块

## 项目阶段
当前阶段：阶段 1 - 双模态 Twitter ABSA 的完全复现与吃透
- 已完成 Twitter-2015 和 Twitter-2017 的 baseline 复现
- 正在进行模型优化和消融实验
- 需要可视化和分析工具辅助调试

## 实验结果记录

### Baseline 结果（已完成）

#### Twitter-2015 最佳配置
```bash
Task: dualc (双模态方面级情感分类)
Text Model: roberta-large
Image Model: vit-large-patch16-224
Batch Size: 16
Learning Rate: 2.26e-05
Alpha: 0.635  # 文本模态权重
Beta: 0.565   # 图像模态权重
Epochs: 80

# 结果
Best F1 (multi): 69.48%
Best F1 (text): 69.17%
Precision (multi): 68.41%
Recall (multi): 70.59%
```

#### Twitter-2017 最佳配置
```bash
Task: dualc
Text Model: roberta-large
Image Model: vit-large-patch16-224
Batch Size: 16
Learning Rate: 2.26e-05
Alpha: 0.635
Beta: 0.565
Epochs: 80

# 结果
Best F1 (multi): 70.35%
Best F1 (text): 70.50%
Precision (multi): 69.57%
Recall (multi): 71.15%

# 对比：2017 比 2015 高 0.87 个百分点
```

### 参数说明
- **Alpha**: 文本模态的融合权重，控制文本特征在跨模态融合中的贡献
- **Beta**: 图像模态的融合权重，控制图像特征在跨模态融合中的贡献
- **Learning Rate**: 建议范围 1e-5 ~ 5e-5，过大容易不收敛
- **Batch Size**: 受 GPU 显存限制，16 是较优选择
- **Epochs**: 80 轮足够收敛，可根据验证集表现提前停止

## 开发原则

### 工作流程（重要）
**用户的工作模式是「先规划，后实验」**

1. **阶段目标文档优先**
   - 用户会先在 `doc/阶段目标文档.md` 中规划任务和实验方案
   - 文档路径：`F:\辅修毕设\ICT源代码\doc\阶段目标文档.md`

2. **主动读取文档**
   - 当用户提到「实验」「调参」「任务」「下一步」时，**主动读取阶段目标文档**
   - 了解当前阶段的目标、已完成的实验、待执行的计划、用户记录的问题

3. **基于文档给建议**
   - 根据文档中的规划给出参数建议、实验方案
   - 不要凭空猜测，要基于用户已经写好的计划

4. **实验由用户执行**
   - 一般不需要替用户执行实验（除非明确要求）
   - 提供清晰的命令和参数配置即可

### 代码规范
- 保持代码简洁，避免过度工程化
- 优先修改现有代码，避免创建新文件
- 不要添加不必要的注释和文档字符串
- 使用中文注释（项目原有风格）

### Git 管理
- 大文件（模型权重 *.pth、数据集）不提交到 Git
- 提交信息要清晰描述改动内容
- 定期推送到远程仓库备份

### 实验管理
- 可视化输出保存到 *_vis/ 目录
- 日志文件用于调试记录
- checkpoint 保存训练中间状态

## 重要文件说明
- `main.py` - 主训练脚本
- `model.py` - 核心模型定义
- `TrainInputProcess.py` - 数据预处理
- `eval_checkpoint.py` - 模型评估
- `visualize_*.py` - 各类可视化工具

## 服务器实验流程

### 服务器信息
- 服务器地址：`ssh root@8.138.115.47`
- 工作目录：`/root/ICT-main/`
- GPU 环境：CUDA 可用

### 上传代码到服务器
```bash
# 方法1：使用 scp 上传单个文件
scp <本地文件路径> root@8.138.115.47:/root/ICT-main/

# 方法2：使用 scp 上传整个目录
scp -r <本地目录> root@8.138.115.47:/root/ICT-main/

# 方法3：使用 Git（推荐）
# 在服务器上：
cd /root/ICT-main
git pull origin master
```

### 训练命令
```bash
# SSH 登录服务器
ssh root@8.138.115.47

# 进入项目目录
cd /root/ICT-main

# 使用 nohup 后台训练（推荐）
nohup python main.py > training.log 2>&1 &

# 或使用 screen/tmux 会话训练
screen -S ict_training
python main.py
# Ctrl+A+D 分离会话

# 查看训练日志
tail -f training.log

# 查看 GPU 使用情况
nvidia-smi

# 查看后台进程
ps aux | grep python
```

### 下载结果
```bash
# 下载训练好的模型
scp root@8.138.115.47:/root/ICT-main/checkpoint/*.pth ./checkpoint/

# 下载可视化结果
scp -r root@8.138.115.47:/root/ICT-main/*_vis/ ./

# 下载日志文件
scp root@8.138.115.47:/root/ICT-main/training.log ./
```

### 常见操作
```bash
# 停止训练进程
pkill -f "python main.py"

# 清理旧的 checkpoint
rm -rf checkpoint/old_*.pth

# 检查磁盘空间
df -h

# 查看目录大小
du -sh /root/ICT-main/*
```

## 注意事项
- 模型文件很大（2.7GB），已在 .gitignore 中排除
- 使用 GPU 训练，注意显存管理
- 实验结果需要可视化分析以便论文撰写
- 服务器训练时使用 nohup 或 screen 避免断线中断
- 定期下载 checkpoint 到本地备份
